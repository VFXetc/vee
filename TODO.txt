
BEFORE FIRST DEPLOY
-------------------

- try to unify the arguments and attributes on Package and Requirement
- dev environment
- test everything?!
- key_base
    - entrypoints
    - apps: can we build them in a central location, outside of the isolated
      build environments, or is the Finder going to be able to adapt to symlinks
      in the Dock?
    - scrap history
- OS X apps via symlinks in docks?
- assert all westernx packages transition


    - entrypoints.yml at top_level is built by Makefile (in sgfs and others)
        - make a build_metatools_entrypoints distutils command
    - sgactions.yml at top_level is built by Makefile (in sgfs and others)
        - this becomes the user's problem


---

- commands to write:
    - vee gc [--installs] [--environs]
        - delete installs (and their DB records) which are not linked to
        - delete installs in DB that don't exist on disk
        - delete anything on disk that isn't referred to by the index
            build a set of relative paths (and all their ancestors), then walk the
            root looking for directories which aren't mentioned, then delete them
    - vee uninstall (NAME|REQUIREMENT [ARGS])
    - vee unlink ENVIRON (NAME|REQUIREMENT [ARGS])

    - vee develop (NAME|REQUIREMENT)

        - clone the project into $VEE_DEV
        - pkg.builder.develop()
        - INSERT INTO packages (develop_path) VALUES (?)
            OR
          INSERT INTO dev_packages (name, url, path)

        - vee develop [--path PATH] name
            - if the path already exists and is a git repo, then it just links
              it up
            - if the git repo doesnt exist, then it makes it
        - vee develop --init name
            - it makes a new package, and assumes it 
        - vee develop --build [NAME|PATH]
            - make a Package, set the build path, get a Builder, and call develop()

        - it looks at the origin later to figure this nonsense out



    - dev [...] COMMAND [ARGS]
        - runtime linking of dev tools over default repo

    - vee add [NAME|PATH]
        - add new commits to the repo requirements

    - vee status
        - check on status of each dev tool, and where they are vs the repo

    - vee commit [--major,--minor,--patch] [-m MESSAGE]
        - commit the current state of the repo

    - vee push
        - push all tools that aren't already, and the repo

    - vee list
        - list packages, environments, etc..


---


- set:path/to/sets for sets

- normalization of git URLs:
    git+user@host:path/to/repo -> git+ssh://user@host/path/to/repo

- VEE_DEV=$VEE/dev by default, but is only really used by `vee develop` and `dev -u USER`
- VEE_REPO=westernx sets the default repo

- permissions

    - install_vee.py
        - just warn if they are running as root, but don't stop them
        - default to assuming a single user
        - --multi-user signals that it should try to setup a group setup, OR we
          can just let them figure that out themselves

    - `vee doctor` should do the main permission checks

    - do we need to set our umask, or can permission bits somehow handle that?
        - document the result
    - do we need to chgrp, or can setgid handle that?
        - document the result

- test python packages (for each of source, sdist, bdist, bdist_wheel):
    - they import
    - they import each other
    - console_scripts entrypoints work
    - scripts work
    - their install_requires doesn't matter

- install data that comes with Python wheels
  $NAME-$VERSION.data dir at top-level, beside $NAME-$VERSION.dist-info

- install Python commands listed in egg-info

- linking should check if a previous revision of the same thing was already
  linked into an environment, and stop you

- how does this new Python install method deal with install_requires?
    - it doesn't! document it?

- s/Home/Vee/g ??

- does it make sense to have packages/builds/installs separate in the database,
  instead of having them all together under "packages"

- build-subdir and install-prefix should be used to invalidate matches in the
  resolver

- does sitetools disprove the separate Python build/install process?

- git might need to use different revisions on different platforms (for homebrew/linuxbrew)
    - if this is the only attribute that matters in this way, then we can have a
        --linux-revision and --osx-revision which it picks from
    - `--revision:osx` or `osx:--revision`

- '--refresh' or --latest' or '--head' to always request the latest; this is a more general
  case of --force-fetch

- log everything about the different steps, and stuff it into the database
- CLI IO/API/logging package

    - name:
        x clio (on PyPI)
        - clout

    - styles (copied straight from what we have is cool)
    - io indenting model
        - replaces sys.stdout and sys.stderr, and those are pushed through
        - can spawn reader threads which can (1) buffer the output, (2) echo it, (3) push it to a callback
        - with clout.io.indent(), or clout.io.push_indent() and clout.io.pop_indent()
    - event log
        - format: "$datetime $stream $string-escaped-content"
        - events:
            - exec:$pid -> nth executable
            - arg:$pid:I -> argument I of nth exe
            - out:$pid -> stdout of nth exe
            - err:$pid -> stderr of nth exe

- Home.{package,build,install,develop,environment}_root attributes
- Home.to_environ()

- record stdout/stderr from build process in the database. Use a timestamped
  format: each line starts with "out" or "err" and the timestamp

    out 2015-02-18T15:02:01 sdflkjsdf

- Http/File/Base could do checksums of files to see if they have changed
  - memoize the caches based on inode,size,mtime

- cythonmagick is pulling in the "wrong" sqlite?


LATER
-----

- custom managers
  - e.g. `vee install PyAV.py`, where PyAV.py contains:
        - REQUIREMENT = 'https://pypi.python.org/packages/source/a/av/av-0.2.2.tar.gz#md5=ec0198f28d9294d20b54b0ac3a9ff77d'
        - DEPENDS_ON = ['lib:ffmpeg']
        - MANAGER or PyAVManager or PyavManager, which inherits from BaseManager

- pypi manager
    - PyPI JSON API -> https://pypi.python.org/pypi/%s/json
    - Need to either hit the PyPI on every `.installed` check, or cache versions.

- match how Homebrew links directories, or at least be smarter about it

- homebrew taps: homebrew+mikeboers/testbrew/foo
    - we would need a way to detect which tap it is
    - we can grep `brew info $forumla` for From: https://github.com/#{user}/#{repo}/blob/master/#{path}

- Requirement.dependencies() and Requirement.provisions()

  An AbstractRequirement is one like "lib:ffmpeg", "py:yaml", etc., that just
  know what result they want, but not where it is from. A DependencyInterface
  could be the intersection of AbstractRequirement and Requirement, such that

  Requirement.dependencies() can return real ones (e.g. from `brew deps`)
  and abstract ones. It is permitted to return different dependencies on each
  call (as they are discovered, e.g.)

  DependencyResolver can take a pool of requirements and figure out what order
  they should be installed in (via C3)

        .add(requirement)
        .rescan_dependencies()
        .linearize()


  