
BEFORE FIRST DEPLOY
-------------------

√ try to unify the arguments and attributes on Package and Requirement
~ dev environment
~ test everything?!
- key_base
    - entrypoints
    - apps: can we build them in a central location, outside of the isolated
      build environments, or is the Finder going to be able to adapt to symlinks
      in the Dock?
    - scrap history
- OS X apps via symlinks in docks?
- assert all westernx packages transition

    - entrypoints.yml at top_level is built by Makefile (in sgfs and others)
        - make a build_metatools_entrypoints distutils command
    - sgactions.yml at top_level is built by Makefile (in sgfs and others)
        - this becomes the user's problem


COMMANDS TO WRITE
-----------------

  - vee gc [--installs] [--environs]
      - delete installs (and their DB records) which are not linked to
      - delete installs in DB that don't exist on disk
      - delete anything on disk that isn't referred to by the index
          build a set of relative paths (and all their ancestors), then walk the
          root looking for directories which aren't mentioned, then delete them

  - vee uninstall (NAME|REQUIREMENT [ARGS])
  - vee unlink ENVIRON (NAME|REQUIREMENT [ARGS])

  ~ vee develop ...
  ~ dev [...] COMMAND [ARGS]
      - runtime linking of dev tools over default repo

  ~ vee add [NAME|PATH]
      - add new commits to the repo requirements
  ~ vee add --bake-installed
      - update the repo to the current revision of everything that is
        installed
  ~ vee add --update

  √ vee update
  √ vee upgrade

  - vee status
      - check on status of each dev tool, and where they are vs the repo
      - check on work tree vs. index vs. head of the repo too, like git status
          index: `git show :requirements.txt`
          head: `git show HEAD:requirements.txt`

  ~ vee commit [--major,--minor,--patch] [-m MESSAGE]

  - vee push [--no-dev]
      - push all packages that aren't already, and the repo

  - vee list
      - list packages, environments, etc..

  - vee freeze [-e ENV] [-R req] [-r repo] [DST_REPO]
      - freeze all requirements into a repository
      - this uses much of the same code from `vee exec` and `vee add`


---

- test `vee add .`, `vee commit .`

- s/RequirementSet/???
    - EnvironmentRequirements
    - EnvironRequirements
    - EnvRequirements
    - BuildOrder
    - EnvironmentSpecification
    - Recipie

- rename EnvironmentRepo.load_requirements() and dump_requirements()

- is it possible for me to bundle libgit2, and build it?

- there are a ton of times we need to guess which dev remote to use; perhaps
  we should have a remote/branch to track in the database, OR figure out how
  to interpret that from the repo itself. Git seems to store a repo per branch,
  so we could always look at the active branch
  
- move `vee repo git` back to `vee git` ??

- normalize_git_url(prefer='https'); then you can convert GitHub's http/scp
  back and forth (so that dev uses ssh and repos use https)

- RequirementSet elements should be their own class:
    - el.path is path to file that contained it

- merge Requirement into Package

    Package.factory(args)
    make_package(args)

    it is nice having them be separate, and one being user specifications
    perhaps an AbstractPackage would fit the bill

- preprocessing for requirement files?
    #if VEE_PLATFORM == "darwin"
    #elif
    #else
    #end


- permissions

    - install_vee.py
        - just warn if they are running as root, but don't stop them
        - default to assuming a single user
        - --multi-user signals that it should try to setup a group setup, OR we
          can just let them figure that out themselves

    - `vee doctor` should do the main permission checks

    - do we need to set our umask, or can permission bits somehow handle that?
        - document the result
    - do we need to chgrp, or can setgid handle that?
        - document the result

- test python packages (for each of source, sdist, bdist, bdist_wheel):
    - they import
    - they import each other
    - console_scripts entrypoints work
    - scripts work
    - their install_requires doesn't matter

- install data that comes with Python wheels
  $NAME-$VERSION.data dir at top-level, beside $NAME-$VERSION.dist-info

- install Python commands listed in egg-info

- linking should check if a previous revision of the same thing was already
  linked into an environment, and stop you

    - Package.resolve_existing(any_revision=True)

- does it make sense to have packages/builds/installs separate in the database,
  instead of having them all together under "packages"

- build-subdir and install-prefix should be used to invalidate matches in the
  resolve_existing

- log everything about the different steps, and stuff it into the database
- CLI IO/API/logging package

    - name:
        x clio (on PyPI)
        - clout

    - styles (copied straight from what we have is cool)
    - io indenting model
        - replaces sys.stdout and sys.stderr, and those are pushed through
        - can spawn reader threads which can (1) buffer the output, (2) echo it, (3) push it to a callback
        - with clout.io.indent(), or clout.io.push_indent() and clout.io.pop_indent()
    - event log
        - format: "$datetime $stream $string-escaped-content"
        - events:
            - exec:$pid -> nth executable
            - arg:$pid:I -> argument I of nth exe
            - out:$pid -> stdout of nth exe
            - err:$pid -> stderr of nth exe

- Home.{package,build,install,develop,environment}_root attributes
- Home.to_environ()

- record stdout/stderr from build process in the database. Use a timestamped
  format: each line starts with "out" or "err" and the timestamp

    out 2015-02-18T15:02:01 sdflkjsdf

- Http/File/Base could do checksums of files to see if they have changed
  - memoize the caches based on inode,size,mtime

- cythonmagick is pulling in the "wrong" sqlite?


LATER
-----

- custom managers
  - e.g. `vee install PyAV.py`, where PyAV.py contains:
        - REQUIREMENT = 'https://pypi.python.org/packages/source/a/av/av-0.2.2.tar.gz#md5=ec0198f28d9294d20b54b0ac3a9ff77d'
        - DEPENDS_ON = ['lib:ffmpeg']
        - MANAGER or PyAVManager or PyavManager, which inherits from BaseManager

- pypi manager
    - PyPI JSON API -> https://pypi.python.org/pypi/%s/json
    - Need to either hit the PyPI on every `.installed` check, or cache versions.

- match how Homebrew links directories, or at least be smarter about it

- homebrew taps: homebrew+mikeboers/testbrew/foo
    - we would need a way to detect which tap it is
    - we can grep `brew info $forumla` for From: https://github.com/#{user}/#{repo}/blob/master/#{path}

- Requirement.dependencies() and Requirement.provisions()

  An AbstractRequirement is one like "lib:ffmpeg", "py:yaml", etc., that just
  know what result they want, but not where it is from. A DependencyInterface
  could be the intersection of AbstractRequirement and Requirement, such that

  Requirement.dependencies() can return real ones (e.g. from `brew deps`)
  and abstract ones. It is permitted to return different dependencies on each
  call (as they are discovered, e.g.)

  DependencyResolver can take a pool of requirements and figure out what order
  they should be installed in (via C3)

        .add(requirement)
        .rescan_dependencies()
        .linearize()


  